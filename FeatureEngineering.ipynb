{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier  # Import XGBoost classifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pprint \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('./DATA/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BBL_20_2.0', 'BBM_20_2.0', 'BBU_20_2.0', 'BBB_20_2.0', 'BBP_20_2.0'], dtype='object')\n",
      "Index(['BBL_20_2.0', 'BBM_20_2.0', 'BBU_20_2.0', 'BBB_20_2.0', 'BBP_20_2.0'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Momentum Indicators\n",
    "data['ema_diff_9'] = data['close'] - data['9_ema']\n",
    "data['ema_diff_21'] = data['close'] - data['21_ema']\n",
    "data['ema_diff_50'] = data['close'] - data['50_ema']\n",
    "data['ema_diff_200'] = data['close'] - data['200_ema']\n",
    "data['roc_9'] = data['close'].pct_change(periods=9)\n",
    "data['roc_21'] = data['close'].pct_change(periods=21)\n",
    "# Volatility Indicators\n",
    "data['atr_14'] = data['high'].pct_change().rolling(14).apply(lambda x: np.sum(np.abs(x))).rolling(14).mean()\n",
    "bb = ta.bbands(data['close'], length=20, scalar=2)\n",
    "bb_column_names = bb.columns\n",
    "\n",
    "# Check the column names\n",
    "print(bb_column_names)\n",
    "\n",
    "# Assign the correct column names\n",
    "data['bb_upper'] = bb[bb_column_names[0]]\n",
    "data['bb_middle'] = bb[bb_column_names[1]]\n",
    "data['bb_lower'] = bb[bb_column_names[2]]\n",
    "\n",
    "\n",
    "# On-chain Indicators\n",
    "data['mvrv_zscore'] = (data['mvrv'] - data['mvrv'].rolling(30).mean()) / data['mvrv'].rolling(30).std()\n",
    "data['nupl_zscore'] = (data['nupl'] - data['nupl'].rolling(30).mean()) / data['nupl'].rolling(30).std()\n",
    "\n",
    "\n",
    "# Momentum Indicators for Fear and Greed Index\n",
    "data['fg_roc_9'] = data['Fear_and_Greed_Index'].pct_change(periods=9)\n",
    "data['fg_roc_21'] = data['Fear_and_Greed_Index'].pct_change(periods=21)\n",
    "data['fg_ema_9'] = data['Fear_and_Greed_Index'].ewm(span=9, adjust=False).mean()\n",
    "data['fg_ema_21'] = data['Fear_and_Greed_Index'].ewm(span=21, adjust=False).mean()\n",
    "\n",
    "# Volatility Indicators for Fear and Greed Index\n",
    "data['fg_atr_14'] = data['Fear_and_Greed_Index'].pct_change().rolling(14).apply(lambda x: np.sum(np.abs(x))).rolling(14).mean()\n",
    "bb = ta.bbands(data['Fear_and_Greed_Index'], length=20, scalar=2)\n",
    "bb_column_names = bb.columns\n",
    "\n",
    "# Check the column names\n",
    "print(bb_column_names)\n",
    "\n",
    "# Assign the correct column names\n",
    "data['bb_upper'] = bb[bb_column_names[0]]\n",
    "data['bb_middle'] = bb[bb_column_names[1]]\n",
    "data['bb_lower'] = bb[bb_column_names[2]]\n",
    "\n",
    "\n",
    "# Fear and Greed Index Extremes\n",
    "data['fg_extreme_fear'] = (data['Fear_and_Greed_Index'] < 20).astype(int)\n",
    "data['fg_extreme_greed'] = (data['Fear_and_Greed_Index'] > 80).astype(int)\n",
    "\n",
    "# Fear and Greed Index Signals\n",
    "data['fg_buy_signal'] = np.where((data['Fear_and_Greed_Index'].shift(1) < 25) & (data['Fear_and_Greed_Index'] >= 25), 1, 0)\n",
    "data['fg_sell_signal'] = np.where((data['Fear_and_Greed_Index'].shift(1) > 75) & (data['Fear_and_Greed_Index'] <= 75), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is your DataFrame and 'signal' is the target variable\n",
    "X = data.drop(['signal', 'datetime'], axis=1)  # Exclude 'datetime' for model training\n",
    "y = data['signal'].map({'buy': 0, 'sell': 1, 'none': 2}).astype(int)  # Encoding signals\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8235294117647058\n",
      "Class Accuracy:\n",
      "{   '0': {   'f1-score': 0.2758620689655173,\n",
      "             'precision': 0.4444444444444444,\n",
      "             'recall': 0.2,\n",
      "             'support': 20.0},\n",
      "    '1': {   'f1-score': 0.5714285714285714,\n",
      "             'precision': 0.8888888888888888,\n",
      "             'recall': 0.42105263157894735,\n",
      "             'support': 19.0},\n",
      "    '2': {   'f1-score': 0.8958990536277601,\n",
      "             'precision': 0.8402366863905325,\n",
      "             'recall': 0.9594594594594594,\n",
      "             'support': 148.0},\n",
      "    'accuracy': 0.8235294117647058,\n",
      "    'macro avg': {   'f1-score': 0.5810632313406163,\n",
      "                     'precision': 0.7245233399079553,\n",
      "                     'recall': 0.5268373636794689,\n",
      "                     'support': 187.0},\n",
      "    'weighted avg': {   'f1-score': 0.7966173485206509,\n",
      "                        'precision': 0.8028492372383775,\n",
      "                        'recall': 0.8235294117647058,\n",
      "                        'support': 187.0}}\n",
      "Confusion Matrix:\n",
      "[[  4   0  16]\n",
      " [  0   8  11]\n",
      " [  5   1 142]]\n"
     ]
    }
   ],
   "source": [
    "# Define class weights\n",
    "class_weights_custom = {0: 10, 1: 10, 2: 1}\n",
    "\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "# Initialize XGBoost classifier with class weights\n",
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight=class_weights_custom,\n",
    "    y=y_train\n",
    ")\n",
    "# Train the classifier\n",
    "xgb_classifier.fit(X_train_scaled, y_train, sample_weight=classes_weights)\n",
    "\n",
    "# Predict signals on the test set\n",
    "y_pred = xgb_classifier.predict(X_test_scaled)\n",
    "\n",
    "#Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate class accuracy, f1 score, and confusion matrix\n",
    "class_accuracy = classification_report(y_test, y_pred, output_dict=True)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Class Accuracy:\")\n",
    "pp.pprint(class_accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
